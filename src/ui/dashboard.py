import time
import httpx
import pandas as pd
import streamlit as st

# CONFIGURATION
API_URL = "http://api:8000"

st.set_page_config(page_title="BugLens AI Dashboard", layout="wide")

# CUSTOM CSS FOR BETTER VISUALS
st.markdown(
    """
    <style>
    [data-testid="stMetric"] {
        background-color: rgba(28, 131, 225, 0.1);
        padding: 15px;
        border-radius: 10px;
        border: 1px solid rgba(28, 131, 225, 0.2);
    }
    </style>
    """,
    unsafe_allow_html=True,
)


# REFRESH FRAGMENT
@st.fragment(run_every="30s")
def render_job_table():
    jobs = []
    try:
        response = httpx.get(f"{API_URL}/jobs")
        jobs = response.json()
        if jobs:
            df = pd.DataFrame(jobs)
    except httpx.HTTPError:
        st.error("Connection lost.")
    if jobs:
        df = pd.DataFrame(jobs)
        # Toast notification for background work
        processing = df[df["status"] == "PROCESSING"]
        if not processing.empty:
            st.toast(f"AI is analyzing {len(processing)} video(s)...", icon="‚è≥")

        # Display simplified table
        cols_to_show = ["id", "status", "created_at", "filename"]
        st.dataframe(df[cols_to_show], width="content", hide_index=True)
        return jobs
    return []


# HEADER & METRICS
st.title("BugLens AI: Video Bug Reports")

# Initial fetch for metrics
try:
    initial_jobs = httpx.get(f"{API_URL}/jobs").json()
except httpx.HTTPError as e:
    initial_jobs = []
    st.error(f"Error fetching jobs: {e}")

m1, m2, m3 = st.columns(3)
m1.metric("Total Reports", len(initial_jobs))
m2.metric("System Status", "Online" if initial_jobs is not None else "Offline")
m3.metric("AI Engine", "Llama 3.2 (Ollama)")

st.divider()

# SIDEBAR: UPLOAD
with st.sidebar:
    st.header("Upload New Video")
    uploaded_file = st.file_uploader("Drop bug recording here...", type=["mp4", "mov"])

    if st.button("Submit to Pipeline", width="content") and uploaded_file:
        with st.spinner("Uploading..."):
            files = {"file": (uploaded_file.name, uploaded_file.getvalue())}
            res = httpx.post(f"{API_URL}/upload", files=files)
            if res.status_code == 200:
                st.success(f"Job Queued: {res.json()['job_id'][:8]}")
                st.rerun()

    st.divider()
    st.info(
        "**Tip:** Speak clearly during the recording so Whisper can catch the bug context."
    )

# MAIN CONTENT: JOB LIST
st.header("Recent Reports")
jobs_list = render_job_table()

# JOB DETAILS SECTION
if jobs_list:
    st.divider()
    selected_id = st.selectbox(
        "Select a Job to Investigate", [j["id"] for j in jobs_list]
    )

    if selected_id:
        detail = httpx.get(f"{API_URL}/status/{selected_id}").json()

        # Action Bar: Delete & Export
        if st.button("Delete Job", type="primary"):
            with st.spinner("Deleting..."):
                try:
                    response = httpx.delete(f"{API_URL}/jobs/{selected_id}")
                    if response.status_code == 200:
                        st.success("Job deleted successfully!")
                        time.sleep(1)
                        st.rerun()
                    else:
                        st.error(f"API Error {response.status_code}: {response.text}")
                except Exception as e:
                    st.error(f"Connection Error: {e}")

        # Analysis Side-by-Side
        col_l, col_r = st.columns(2)

        with col_l:
            st.subheader("AI Analysis")
            status = detail.get("status")

            if status == "COMPLETED":
                summary = detail.get("summary", "Summary missing.")
                st.markdown(summary)

                # Export to Markdown for Jira/GitHub
                report_md = f"# BUG REPORT: {selected_id}\n\n{summary}\n\\n*Generated by BugLens AI*"
                st.download_button(
                    label="Export to Jira/GitHub",
                    data=report_md,
                    file_name=f"bug_report_{selected_id[:8]}.md",
                    mime="text/markdown",
                    width="content",
                )
            elif status == "PROCESSING":
                st.warning("Worker is currently running YOLOv8 and Whisper...")
                st.progress(65)
            elif status == "FAILED":
                st.error(f"Error: {detail.get('error_message')}")

        with col_r:
            st.subheader("Metadata & Logs")
            status = detail.get("status")
            result_data = detail.get("result")

            if status == "COMPLETED" and result_data:
                with st.expander("View Raw Fusion Data", expanded=True):
                    st.json(result_data)
            elif status == "PROCESSING":
                st.info("Metadata is being generated...")
                st.caption(
                    "Whisper transcript and YOLO logs will appear here once the 'Vision' stage finishes."
                )
            else:
                st.info("Metadata not available yet.")
else:
    st.info("No reports found yet. Use the sidebar to upload your first video.")
